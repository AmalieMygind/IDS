{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment the data considered contain information on the occupancy of buildings relevant for potential energy saving. The data will be treated in three different ways: classification will be performed using a nearest neighbor classification algorithm, model selection will be performed using cross-validation and lastly the data will be standard normalized for preprocessing. \n",
    "\n",
    "The data are split into a training set for training a model and a testing set for testing the accuracy of the model. For each data set the first five columns contain data on temperature, relative humidity, light, CO2 and humidity ratio and work as the X-values. The sixth and last column of each data set contain the occupancy data and work as the y-values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "dataTrain = np.loadtxt('.\\OccupancyTrain.csv', delimiter=',')\n",
    "dataTest = np.loadtxt('.\\OccupancyTest.csv', delimiter=',')\n",
    "\n",
    "#split input variables and labels\n",
    "XTrain = dataTrain[:, :-1]\n",
    "YTrain = dataTrain[:, -1]\n",
    "XTest = dataTest[:, :-1]\n",
    "YTest = dataTest[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above classification of the data is performed using a nearest neighbor classifier. The nearest neighbor classification function is defined below. The function assigns a classifier to each point in the data set based on what classfier the k nearest neighbors of the point have been assigned. The k nearest neighbors are defined as the k points with the shortest euclidian distance to the point in question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define k-NN function \n",
    "def kNN(XTrain, YTrain, XTest, k):\n",
    "    outputs = []\n",
    "    for i in range(len(XTest)):\n",
    "        distances = []\n",
    "        for n in range(len(XTrain)):\n",
    "            #compute distance to each neighbor and append to list of distances\n",
    "            distances.append(np.sqrt(sum((XTrain[n][m]-XTest[i][m])**2 for m in range(len(XTrain[0])))))\n",
    "        #classifiers for k nearest neighbors \n",
    "        k_nearest = [YTrain[neighbor_index] for neighbor_index in np.argsort(distances)[:k]]    \n",
    "        #choose classifier most common in k nearest neighbors and append to list of outputs\n",
    "        outputs.append(np.argmax(np.bincount(k_nearest)))\n",
    "    \n",
    "    return np.round(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the classification function is tested below for k = 1 i.e. where the classifier for only the single nearest neighbor determines the classifier for a data point. The testing of the accuracy of the model works by comparing the predicted classfiers from the output of the k-NN function to the actual recorded classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results of 1-NN classifier: 1.0\n",
      "Test results of 1-NN classifier: 0.9775\n"
     ]
    }
   ],
   "source": [
    "#classification accuracy\n",
    "accTrain = accuracy_score(YTrain, kNN(XTrain, YTrain, XTrain, 1))\n",
    "accTest = accuracy_score(YTest, kNN(XTrain, YTrain, XTest, 1))\n",
    "print('Training results of 1-NN classifier: ' + str(accTrain))\n",
    "print('Test results of 1-NN classifier: ' + str(accTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy of the 1-NN classifier implemented above is 1.0 which would be expected as the nearest neighbor for each datapoint is itself and only the single nearest neighbor is considered in 1-NN. The test accuracy is 0.9775, so the model will predict the correct classifier for the test data in this dataset in 97.75% of cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In exercise 1 the accuracy of the nearest neighbor classification was tested for k = 1. However another choice of the hyperparameter k might give a higher accuracy. To determine the best hyperparameter the method of cross validation is used. Specifically 5-fold cross-validation is used meaning that the training data is split into 5 parts whereof 4 parts act as the new training data and the fifth part acts as the new testing data. The best value, k_best, of the hyperparamter k is chosen from {1,3,5,7,9,11}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#model selecting using cross validation \n",
    "def model_selection(k_values, XTrain, YTrain):\n",
    "    accuracies = []\n",
    "    #splitting training data into 5 parts\n",
    "    cv = KFold(n_splits=5)\n",
    "    for k in ks:\n",
    "        k_specific_accuracies = []\n",
    "        for train_index, test_index in cv.split(XTrain):\n",
    "            XTrainCV, XTestCV, YTrainCV, YTestCV = XTrain[train_index], XTrain[test_index], YTrain[train_index], YTrain[test_index]\n",
    "            #test accuracy of kNN for given k \n",
    "            k_specific_accuracies.append(accuracy_score(YTestCV, kNN(XTrainCV, YTrainCV, XTestCV, k)))\n",
    "        accuracies.append(np.round(np.mean(k_specific_accuracies),4))\n",
    "\n",
    "    #find best k as the one with highest mean accuracy\n",
    "    best_k = ks[np.argmax(accuracies)]\n",
    "    return best_k\n",
    "\n",
    "ks = [1,3,5,7,9,11]\n",
    "print(model_selection(ks, XTrain, YTrain))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each value of k the training data was split into five parts. For each of five rounds XTrainCV, XTestCV, YTrainCV and YTestCV  were defined and the kNN function was run with XTrainCV, YTrainCV, XTestCV and k as input to give YTestCV. Then the accuracy of the kNN function for each of the five rounds was computed by comparing the output of the kNN function to YTestCV. Then the average accuracy for the given k was computed as the mean for each of the five rounds. The procedure was repeated for each k-value, and the k-value with highest average accuracy (lowest 0-1 loss) was chosen as k_best. \n",
    "\n",
    "The value of k_best was computed to be 3, so according to the model, taking the 3 nearest neighbors into consideration gives the most accurate classifier for this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In exercise 2 the value of the hyperparameter k_best was found to be 3. The accuracy of the k_best-NN classifier is now tested on the complete data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results of k_best-NN classifier: 0.9933333333333333\n",
      "Test results of k_best-NN classifier: 0.9875\n"
     ]
    }
   ],
   "source": [
    "#training and test accuracy of k_best\n",
    "k_best = 3\n",
    "accTrain_kbest = accuracy_score(YTrain, kNN(XTrain, YTrain, XTrain, k_best))\n",
    "accTest_kbest = accuracy_score(YTest, kNN(XTrain, YTrain, XTest, k_best))\n",
    "print('Training results of k_best-NN classifier: ' + str(accTrain_kbest))\n",
    "print('Test results of k_best-NN classifier: ' + str(accTest_kbest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training accuracy of k_best = 3 is 0.9933.\n",
    "The test accuracy of k_best = 3 is 0.9875. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 {-}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a preprocessing step normalization of the data is now performed. The data is normalized to generate zero-mean, unit variance input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize training data\n",
    "XTrainN = np.array([(XTrain[:,i]-np.mean(XTrain[:,i]))/np.std(XTrain[:,i]) for i in range(len(XTrain[0]))]).T\n",
    "XTestN = np.array([(XTest[:,i]-np.mean(XTrain[:,i]))/np.std(XTrain[:,i]) for i in range(len(XTest[0]))]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data have now been normalized the selection of the best value of the hyperparamter k_best is repeated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#model-selecting using normalized training data\n",
    "ks = [1,3,5,7,9,11]\n",
    "print(model_selection(ks, XTrainN, YTrain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having determined the k_best value for the normalized data the accuracy testing of the k_best-NN model is also repeated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results of k_best-NN classifier for normalized data: 0.9933333333333333\n",
      "Test results of k_best-NN classifier for normalized data: 0.9875\n"
     ]
    }
   ],
   "source": [
    "#training and test accuracy of k_best for normalized data\n",
    "k_best = 3\n",
    "accTrain_kbest_N = accuracy_score(YTrain, kNN(XTrainN, YTrain, XTrainN, k_best))\n",
    "accTest_kbest_N = accuracy_score(YTest, kNN(XTrainN, YTrain, XTestN, k_best))\n",
    "print('Training results of k_best-NN classifier for normalized data: ' + str(accTrain_kbest_N))\n",
    "print('Test results of k_best-NN classifier for normalized data: ' + str(accTest_kbest_N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalization of the data k_best is still found to be 3 through cross-validation. The training accuracy of k_best = 3 is still 0.9933 and the test accuracy of k_best = 3 is still 0.9875, so the accuracies have not changed after normalization of the data. \n",
    "\n",
    "Considering the three different ways one could have applied the preprocessing from scikit-learn:\n",
    "Version 1 is the correct version for this use. In version 1 the mean and standard deviation from the training set is used to normalize both the training set and the test set. \n",
    "In version 2 and version 3 the mean and the standard deviation for both the training set and the test set is used for normalization. This is flawed since we don't want to use any information from the test set for cross validation and the model selection. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
